{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 4.8834\n",
      "Epoch 1: loss improved from inf to 3.47003, saving model to best_model.h5\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 3.4700\n",
      "Epoch 2/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 2.1056\n",
      "Epoch 2: loss improved from 3.47003 to 1.75149, saving model to best_model.h5\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 1.7515\n",
      "Epoch 3/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.6751\n",
      "Epoch 3: loss improved from 1.75149 to 1.51307, saving model to best_model.h5\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 1.5131\n",
      "Epoch 4/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.5734\n",
      "Epoch 4: loss improved from 1.51307 to 1.22682, saving model to best_model.h5\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 1.2268\n",
      "Epoch 5/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.9770\n",
      "Epoch 5: loss improved from 1.22682 to 0.94564, saving model to best_model.h5\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.9456\n",
      "Epoch 6/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.8625\n",
      "Epoch 6: loss improved from 0.94564 to 0.70988, saving model to best_model.h5\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7099\n",
      "Epoch 7/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.5032\n",
      "Epoch 7: loss improved from 0.70988 to 0.50304, saving model to best_model.h5\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.5030\n",
      "Epoch 8/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.3030\n",
      "Epoch 8: loss improved from 0.50304 to 0.36316, saving model to best_model.h5\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3632\n",
      "Epoch 9/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.3351\n",
      "Epoch 9: loss improved from 0.36316 to 0.27114, saving model to best_model.h5\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.2711\n",
      "Epoch 10/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.2890\n",
      "Epoch 10: loss improved from 0.27114 to 0.22891, saving model to best_model.h5\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.2289\n",
      "Epoch 11/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.1733\n",
      "Epoch 11: loss improved from 0.22891 to 0.20531, saving model to best_model.h5\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.2053\n",
      "Epoch 12/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.1952\n",
      "Epoch 12: loss improved from 0.20531 to 0.17218, saving model to best_model.h5\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.1722\n",
      "Epoch 13/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.1331\n",
      "Epoch 13: loss improved from 0.17218 to 0.10588, saving model to best_model.h5\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.1059\n",
      "Epoch 14/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0660\n",
      "Epoch 14: loss improved from 0.10588 to 0.07094, saving model to best_model.h5\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0709\n",
      "Epoch 15/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0807\n",
      "Epoch 15: loss improved from 0.07094 to 0.06384, saving model to best_model.h5\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.0638\n",
      "Epoch 16/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.0463\n",
      "Epoch 16: loss improved from 0.06384 to 0.04556, saving model to best_model.h5\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.0456\n",
      "Epoch 17/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0371\n",
      "Epoch 17: loss improved from 0.04556 to 0.03577, saving model to best_model.h5\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.0358\n",
      "Epoch 18/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0292\n",
      "Epoch 18: loss did not improve from 0.03577\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0462\n",
      "Epoch 19/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0288\n",
      "Epoch 19: loss improved from 0.03577 to 0.03395, saving model to best_model.h5\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0339\n",
      "Epoch 20/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0207\n",
      "Epoch 20: loss improved from 0.03395 to 0.02715, saving model to best_model.h5\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0271\n",
      "Epoch 21/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0248\n",
      "Epoch 21: loss did not improve from 0.02715\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0541\n",
      "Epoch 22/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0236\n",
      "Epoch 22: loss did not improve from 0.02715\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.0377\n",
      "Epoch 23/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0159\n",
      "Epoch 23: loss did not improve from 0.02715\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0284\n",
      "Epoch 24/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0303\n",
      "Epoch 24: loss improved from 0.02715 to 0.02264, saving model to best_model.h5\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.0226\n",
      "Epoch 25/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0377\n",
      "Epoch 25: loss did not improve from 0.02264\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.0258\n",
      "Epoch 26/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0400\n",
      "Epoch 26: loss did not improve from 0.02264\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0304\n",
      "Epoch 27/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0211\n",
      "Epoch 27: loss did not improve from 0.02264\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.0291\n",
      "Epoch 28/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0159\n",
      "Epoch 28: loss did not improve from 0.02264\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0230\n",
      "Epoch 29/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0139\n",
      "Epoch 29: loss did not improve from 0.02264\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0294\n",
      "Epoch 30/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0185\n",
      "Epoch 30: loss did not improve from 0.02264\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.0287\n",
      "Epoch 31/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0148\n",
      "Epoch 31: loss did not improve from 0.02264\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0243\n",
      "Epoch 32/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0142\n",
      "Epoch 32: loss did not improve from 0.02264\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0312\n",
      "Epoch 33/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0146\n",
      "Epoch 33: loss did not improve from 0.02264\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0306\n",
      "Epoch 34/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0130\n",
      "Epoch 34: loss did not improve from 0.02264\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.0273\n",
      "Epoch 35/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0126\n",
      "Epoch 35: loss did not improve from 0.02264\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.0264\n",
      "Epoch 36/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.0304\n",
      "Epoch 36: loss did not improve from 0.02264\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.0301\n",
      "Epoch 37/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0320\n",
      "Epoch 37: loss did not improve from 0.02264\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0229\n",
      "Epoch 38/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0279\n",
      "Epoch 38: loss improved from 0.02264 to 0.01837, saving model to best_model.h5\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0184\n",
      "Epoch 39/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0218\n",
      "Epoch 39: loss improved from 0.01837 to 0.01833, saving model to best_model.h5\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0183\n",
      "Epoch 40/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0276\n",
      "Epoch 40: loss did not improve from 0.01833\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.0215\n",
      "Epoch 41/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0245\n",
      "Epoch 41: loss did not improve from 0.01833\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0250\n",
      "Epoch 42/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.0334\n",
      "Epoch 42: loss did not improve from 0.01833\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.0329\n",
      "Epoch 43/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0139\n",
      "Epoch 43: loss did not improve from 0.01833\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.0272\n",
      "Epoch 44/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0133\n",
      "Epoch 44: loss improved from 0.01833 to 0.01581, saving model to best_model.h5\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0158\n",
      "Epoch 45/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0129\n",
      "Epoch 45: loss did not improve from 0.01581\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0192\n",
      "Epoch 46/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0097\n",
      "Epoch 46: loss did not improve from 0.01581\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0204\n",
      "Epoch 47/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0158\n",
      "Epoch 47: loss did not improve from 0.01581\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.0179\n",
      "Epoch 48/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0226\n",
      "Epoch 48: loss did not improve from 0.01581\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0204\n",
      "Epoch 49/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0156\n",
      "Epoch 49: loss did not improve from 0.01581\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0187\n",
      "Epoch 50/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0176\n",
      "Epoch 50: loss improved from 0.01581 to 0.01363, saving model to best_model.h5\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0136\n",
      "Epoch 51/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0203\n",
      "Epoch 51: loss did not improve from 0.01363\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0171\n",
      "Epoch 52/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0208\n",
      "Epoch 52: loss did not improve from 0.01363\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0262\n",
      "Epoch 53/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0195\n",
      "Epoch 53: loss did not improve from 0.01363\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0217\n",
      "Epoch 54/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0141\n",
      "Epoch 54: loss did not improve from 0.01363\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0171\n",
      "Epoch 55/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0129\n",
      "Epoch 55: loss did not improve from 0.01363\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0258\n",
      "Epoch 56/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0167\n",
      "Epoch 56: loss did not improve from 0.01363\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0175\n",
      "Epoch 57/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0117\n",
      "Epoch 57: loss improved from 0.01363 to 0.01211, saving model to best_model.h5\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0121\n",
      "Epoch 58/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0124\n",
      "Epoch 58: loss improved from 0.01211 to 0.01103, saving model to best_model.h5\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0110\n",
      "Epoch 59/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0156\n",
      "Epoch 59: loss did not improve from 0.01103\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0117\n",
      "Epoch 60/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0139\n",
      "Epoch 60: loss did not improve from 0.01103\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0124\n",
      "Epoch 61/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0089\n",
      "Epoch 61: loss did not improve from 0.01103\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0123\n",
      "Epoch 62/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0178\n",
      "Epoch 62: loss did not improve from 0.01103\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0147\n",
      "Epoch 63/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0080\n",
      "Epoch 63: loss did not improve from 0.01103\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0161\n",
      "Epoch 64/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0178\n",
      "Epoch 64: loss did not improve from 0.01103\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0141\n",
      "Epoch 65/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0092\n",
      "Epoch 65: loss did not improve from 0.01103\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0113\n",
      "Epoch 66/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0148\n",
      "Epoch 66: loss did not improve from 0.01103\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0117\n",
      "Epoch 67/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0117\n",
      "Epoch 67: loss did not improve from 0.01103\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0114\n",
      "Epoch 68/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0080\n",
      "Epoch 68: loss did not improve from 0.01103\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0142\n",
      "Epoch 69/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0108\n",
      "Epoch 69: loss did not improve from 0.01103\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0266\n",
      "Epoch 70/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0211\n",
      "Epoch 70: loss did not improve from 0.01103\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0196\n",
      "Epoch 71/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0139\n",
      "Epoch 71: loss did not improve from 0.01103\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0185\n",
      "Epoch 72/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0094\n",
      "Epoch 72: loss did not improve from 0.01103\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0116\n",
      "Epoch 73/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0087\n",
      "Epoch 73: loss did not improve from 0.01103\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0111\n",
      "Epoch 74/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0073\n",
      "Epoch 74: loss did not improve from 0.01103\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0118\n",
      "Epoch 75/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0108\n",
      "Epoch 75: loss did not improve from 0.01103\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0116\n",
      "Epoch 76/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0104\n",
      "Epoch 76: loss did not improve from 0.01103\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0118\n",
      "Epoch 77/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0095\n",
      "Epoch 77: loss did not improve from 0.01103\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0130\n",
      "Epoch 78/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0139\n",
      "Epoch 78: loss did not improve from 0.01103\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0131\n",
      "Epoch 79/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0204\n",
      "Epoch 79: loss did not improve from 0.01103\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0139\n",
      "Epoch 80/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0085\n",
      "Epoch 80: loss did not improve from 0.01103\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0143\n",
      "Epoch 81/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0158\n",
      "Epoch 81: loss did not improve from 0.01103\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0146\n",
      "Epoch 82/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0105\n",
      "Epoch 82: loss did not improve from 0.01103\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0138\n",
      "Epoch 83/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0127\n",
      "Epoch 83: loss did not improve from 0.01103\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0128\n",
      "Epoch 84/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0132\n",
      "Epoch 84: loss did not improve from 0.01103\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0128\n",
      "Epoch 85/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0117\n",
      "Epoch 85: loss did not improve from 0.01103\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0131\n",
      "Epoch 86/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0115\n",
      "Epoch 86: loss did not improve from 0.01103\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0207\n",
      "Epoch 87/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0159\n",
      "Epoch 87: loss did not improve from 0.01103\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0146\n",
      "Epoch 88/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0101\n",
      "Epoch 88: loss did not improve from 0.01103\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0116\n",
      "Epoch 89/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0138\n",
      "Epoch 89: loss did not improve from 0.01103\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0146\n",
      "Epoch 90/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0181\n",
      "Epoch 90: loss did not improve from 0.01103\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0243\n",
      "Epoch 91/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0260\n",
      "Epoch 91: loss did not improve from 0.01103\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0278\n",
      "Epoch 92/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0203\n",
      "Epoch 92: loss did not improve from 0.01103\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0192\n",
      "Epoch 93/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0259\n",
      "Epoch 93: loss did not improve from 0.01103\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0220\n",
      "Epoch 94/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0265\n",
      "Epoch 94: loss did not improve from 0.01103\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0160\n",
      "Epoch 95/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0108\n",
      "Epoch 95: loss improved from 0.01103 to 0.01074, saving model to best_model.h5\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0107\n",
      "Epoch 96/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0150\n",
      "Epoch 96: loss did not improve from 0.01074\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0120\n",
      "Epoch 97/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0129\n",
      "Epoch 97: loss did not improve from 0.01074\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.0134\n",
      "Epoch 98/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0112\n",
      "Epoch 98: loss did not improve from 0.01074\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0121\n",
      "Epoch 99/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0104\n",
      "Epoch 99: loss did not improve from 0.01074\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0126\n",
      "Epoch 100/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0133\n",
      "Epoch 100: loss did not improve from 0.01074\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0142\n",
      "Epoch 101/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0112\n",
      "Epoch 101: loss did not improve from 0.01074\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0121\n",
      "Epoch 102/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0133\n",
      "Epoch 102: loss did not improve from 0.01074\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0109\n",
      "Epoch 103/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0085\n",
      "Epoch 103: loss did not improve from 0.01074\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0117\n",
      "Epoch 104/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0129\n",
      "Epoch 104: loss did not improve from 0.01074\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0109\n",
      "Epoch 105/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0131\n",
      "Epoch 105: loss did not improve from 0.01074\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0113\n",
      "Epoch 106/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0093\n",
      "Epoch 106: loss did not improve from 0.01074\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0108\n",
      "Epoch 107/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0072\n",
      "Epoch 107: loss did not improve from 0.01074\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0110\n",
      "Epoch 108/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0096\n",
      "Epoch 108: loss did not improve from 0.01074\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0132\n",
      "Epoch 109/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0103\n",
      "Epoch 109: loss did not improve from 0.01074\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0154\n",
      "Epoch 110/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0260\n",
      "Epoch 110: loss did not improve from 0.01074\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0192\n",
      "Epoch 111/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0140\n",
      "Epoch 111: loss did not improve from 0.01074\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0112\n",
      "Epoch 112/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0197\n",
      "Epoch 112: loss did not improve from 0.01074\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0167\n",
      "Epoch 113/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0100\n",
      "Epoch 113: loss improved from 0.01074 to 0.01049, saving model to best_model.h5\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0105\n",
      "Epoch 114/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0094\n",
      "Epoch 114: loss improved from 0.01049 to 0.01023, saving model to best_model.h5\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0102\n",
      "Epoch 115/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0079\n",
      "Epoch 115: loss improved from 0.01023 to 0.00957, saving model to best_model.h5\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0096\n",
      "Epoch 116/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0106\n",
      "Epoch 116: loss did not improve from 0.00957\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0107\n",
      "Epoch 117/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0154\n",
      "Epoch 117: loss did not improve from 0.00957\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0152\n",
      "Epoch 118/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0060\n",
      "Epoch 118: loss did not improve from 0.00957\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.0102\n",
      "Epoch 119/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0086\n",
      "Epoch 119: loss did not improve from 0.00957\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0105\n",
      "Epoch 120/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0087\n",
      "Epoch 120: loss did not improve from 0.00957\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.0108\n",
      "Epoch 121/500\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.0114\n",
      "Epoch 121: loss did not improve from 0.00957\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.0114\n",
      "Epoch 122/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0102\n",
      "Epoch 122: loss did not improve from 0.00957\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0120\n",
      "Epoch 123/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0144\n",
      "Epoch 123: loss did not improve from 0.00957\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0106\n",
      "Epoch 124/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0156\n",
      "Epoch 124: loss did not improve from 0.00957\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0134\n",
      "Epoch 125/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0056\n",
      "Epoch 125: loss did not improve from 0.00957\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.0125\n",
      "Epoch 126/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0080\n",
      "Epoch 126: loss did not improve from 0.00957\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0112\n",
      "Epoch 127/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0119\n",
      "Epoch 127: loss did not improve from 0.00957\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0147\n",
      "Epoch 128/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0129\n",
      "Epoch 128: loss did not improve from 0.00957\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0113\n",
      "Epoch 129/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0164\n",
      "Epoch 129: loss did not improve from 0.00957\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0123\n",
      "Epoch 130/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0125\n",
      "Epoch 130: loss did not improve from 0.00957\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.0108\n",
      "Epoch 131/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0128\n",
      "Epoch 131: loss did not improve from 0.00957\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0136\n",
      "Epoch 132/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0063\n",
      "Epoch 132: loss did not improve from 0.00957\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0104\n",
      "Epoch 133/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0077\n",
      "Epoch 133: loss did not improve from 0.00957\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.0112\n",
      "Epoch 134/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0115\n",
      "Epoch 134: loss did not improve from 0.00957\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0101\n",
      "Epoch 135/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0106\n",
      "Epoch 135: loss did not improve from 0.00957\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0138\n",
      "Epoch 136/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0171\n",
      "Epoch 136: loss did not improve from 0.00957\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0269\n",
      "Epoch 137/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0335\n",
      "Epoch 137: loss did not improve from 0.00957\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0208\n",
      "Epoch 138/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0152\n",
      "Epoch 138: loss did not improve from 0.00957\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0142\n",
      "Epoch 139/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0152\n",
      "Epoch 139: loss did not improve from 0.00957\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.0145\n",
      "Epoch 140/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0199\n",
      "Epoch 140: loss did not improve from 0.00957\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0150\n",
      "Epoch 141/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0166\n",
      "Epoch 141: loss did not improve from 0.00957\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0118\n",
      "Epoch 142/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0108\n",
      "Epoch 142: loss did not improve from 0.00957\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0098\n",
      "Epoch 143/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0083\n",
      "Epoch 143: loss did not improve from 0.00957\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0124\n",
      "Epoch 144/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0118\n",
      "Epoch 144: loss did not improve from 0.00957\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0130\n",
      "Epoch 145/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0126\n",
      "Epoch 145: loss did not improve from 0.00957\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0100\n",
      "Epoch 146/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0114\n",
      "Epoch 146: loss did not improve from 0.00957\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0112\n",
      "Epoch 147/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0111\n",
      "Epoch 147: loss did not improve from 0.00957\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0130\n",
      "Epoch 148/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0165\n",
      "Epoch 148: loss did not improve from 0.00957\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0123\n",
      "Epoch 149/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0106\n",
      "Epoch 149: loss improved from 0.00957 to 0.00932, saving model to best_model.h5\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0093\n",
      "Epoch 150/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0177\n",
      "Epoch 150: loss did not improve from 0.00932\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0136\n",
      "Epoch 151/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0182\n",
      "Epoch 151: loss did not improve from 0.00932\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0162\n",
      "Epoch 152/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0253\n",
      "Epoch 152: loss did not improve from 0.00932\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0152\n",
      "Epoch 153/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0132\n",
      "Epoch 153: loss did not improve from 0.00932\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0138\n",
      "Epoch 154/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0110\n",
      "Epoch 154: loss did not improve from 0.00932\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0115\n",
      "Epoch 155/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0134\n",
      "Epoch 155: loss did not improve from 0.00932\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.0122\n",
      "Epoch 156/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0130\n",
      "Epoch 156: loss did not improve from 0.00932\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0096\n",
      "Epoch 157/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0101\n",
      "Epoch 157: loss did not improve from 0.00932\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.0119\n",
      "Epoch 158/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0124\n",
      "Epoch 158: loss did not improve from 0.00932\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0099\n",
      "Epoch 159/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0159\n",
      "Epoch 159: loss did not improve from 0.00932\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0100\n",
      "Epoch 160/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0078\n",
      "Epoch 160: loss did not improve from 0.00932\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0116\n",
      "Epoch 161/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0189\n",
      "Epoch 161: loss did not improve from 0.00932\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.0133\n",
      "Epoch 162/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0163\n",
      "Epoch 162: loss did not improve from 0.00932\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0114\n",
      "Epoch 163/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0130\n",
      "Epoch 163: loss did not improve from 0.00932\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0119\n",
      "Epoch 164/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0099\n",
      "Epoch 164: loss did not improve from 0.00932\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0119\n",
      "Epoch 165/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0167\n",
      "Epoch 165: loss did not improve from 0.00932\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0118\n",
      "Epoch 166/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0103\n",
      "Epoch 166: loss did not improve from 0.00932\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0103\n",
      "Epoch 167/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0099\n",
      "Epoch 167: loss did not improve from 0.00932\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0104\n",
      "Epoch 168/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0116\n",
      "Epoch 168: loss did not improve from 0.00932\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0109\n",
      "Epoch 169/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0061\n",
      "Epoch 169: loss did not improve from 0.00932\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0119\n",
      "Epoch 170/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0132\n",
      "Epoch 170: loss did not improve from 0.00932\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0105\n",
      "Epoch 171/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0073\n",
      "Epoch 171: loss did not improve from 0.00932\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0097\n",
      "Epoch 172/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0112\n",
      "Epoch 172: loss did not improve from 0.00932\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0119\n",
      "Epoch 173/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0182\n",
      "Epoch 173: loss did not improve from 0.00932\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0126\n",
      "Epoch 174/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0194\n",
      "Epoch 174: loss did not improve from 0.00932\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0109\n",
      "Epoch 175/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0163\n",
      "Epoch 175: loss did not improve from 0.00932\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0106\n",
      "Epoch 176/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0160\n",
      "Epoch 176: loss did not improve from 0.00932\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0105\n",
      "Epoch 177/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0109\n",
      "Epoch 177: loss did not improve from 0.00932\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0116\n",
      "Epoch 178/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0110\n",
      "Epoch 178: loss did not improve from 0.00932\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0115\n",
      "Epoch 179/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0254\n",
      "Epoch 179: loss did not improve from 0.00932\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0209\n",
      "Epoch 180/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0320\n",
      "Epoch 180: loss did not improve from 0.00932\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0225\n",
      "Epoch 181/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0110\n",
      "Epoch 181: loss did not improve from 0.00932\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0132\n",
      "Epoch 182/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0078\n",
      "Epoch 182: loss did not improve from 0.00932\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0117\n",
      "Epoch 183/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0168\n",
      "Epoch 183: loss did not improve from 0.00932\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0123\n",
      "Epoch 184/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0100\n",
      "Epoch 184: loss did not improve from 0.00932\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.0099\n",
      "Epoch 185/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0182\n",
      "Epoch 185: loss did not improve from 0.00932\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0153\n",
      "Epoch 186/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0132\n",
      "Epoch 186: loss did not improve from 0.00932\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.0120\n",
      "Epoch 187/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0219\n",
      "Epoch 187: loss did not improve from 0.00932\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.0181\n",
      "Epoch 188/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0150\n",
      "Epoch 188: loss did not improve from 0.00932\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.0164\n",
      "Epoch 189/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0216\n",
      "Epoch 189: loss did not improve from 0.00932\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0135\n",
      "Epoch 190/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0119\n",
      "Epoch 190: loss did not improve from 0.00932\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0186\n",
      "Epoch 191/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0142\n",
      "Epoch 191: loss did not improve from 0.00932\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0131\n",
      "Epoch 192/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0193\n",
      "Epoch 192: loss did not improve from 0.00932\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0176\n",
      "Epoch 193/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0270\n",
      "Epoch 193: loss did not improve from 0.00932\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0210\n",
      "Epoch 194/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0252\n",
      "Epoch 194: loss did not improve from 0.00932\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0214\n",
      "Epoch 195/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0146\n",
      "Epoch 195: loss did not improve from 0.00932\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0111\n",
      "Epoch 196/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0131\n",
      "Epoch 196: loss did not improve from 0.00932\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0107\n",
      "Epoch 197/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0136\n",
      "Epoch 197: loss did not improve from 0.00932\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0120\n",
      "Epoch 198/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0138\n",
      "Epoch 198: loss did not improve from 0.00932\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0110\n",
      "Epoch 199/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0079\n",
      "Epoch 199: loss did not improve from 0.00932\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.0110\n",
      "Epoch 200/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0090\n",
      "Epoch 200: loss did not improve from 0.00932\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0097\n",
      "Epoch 201/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0117\n",
      "Epoch 201: loss did not improve from 0.00932\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0106\n",
      "Epoch 202/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0116\n",
      "Epoch 202: loss did not improve from 0.00932\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0116\n",
      "Epoch 203/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0140\n",
      "Epoch 203: loss did not improve from 0.00932\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0209\n",
      "Epoch 204/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0232\n",
      "Epoch 204: loss did not improve from 0.00932\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0135\n",
      "Epoch 205/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0068\n",
      "Epoch 205: loss did not improve from 0.00932\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0137\n",
      "Epoch 206/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0176\n",
      "Epoch 206: loss did not improve from 0.00932\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0172\n",
      "Epoch 207/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0291\n",
      "Epoch 207: loss did not improve from 0.00932\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0302\n",
      "Epoch 208/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0466\n",
      "Epoch 208: loss did not improve from 0.00932\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0254\n",
      "Epoch 209/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0380\n",
      "Epoch 209: loss did not improve from 0.00932\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0207\n",
      "Epoch 210/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0369\n",
      "Epoch 210: loss did not improve from 0.00932\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0326\n",
      "Epoch 211/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0451\n",
      "Epoch 211: loss did not improve from 0.00932\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0380\n",
      "Epoch 212/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0857\n",
      "Epoch 212: loss did not improve from 0.00932\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0484\n",
      "Epoch 213/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0473\n",
      "Epoch 213: loss did not improve from 0.00932\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0250\n",
      "Epoch 214/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0159\n",
      "Epoch 214: loss did not improve from 0.00932\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0205\n",
      "Epoch 215/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0197\n",
      "Epoch 215: loss did not improve from 0.00932\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0158\n",
      "Epoch 216/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0197\n",
      "Epoch 216: loss did not improve from 0.00932\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0154\n",
      "Epoch 217/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0084\n",
      "Epoch 217: loss did not improve from 0.00932\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0144\n",
      "Epoch 218/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0142\n",
      "Epoch 218: loss did not improve from 0.00932\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0251\n",
      "Epoch 219/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0202\n",
      "Epoch 219: loss did not improve from 0.00932\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0173\n",
      "Epoch 220/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0157\n",
      "Epoch 220: loss did not improve from 0.00932\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0109\n",
      "Epoch 221/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0097\n",
      "Epoch 221: loss did not improve from 0.00932\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0098\n",
      "Epoch 222/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0087\n",
      "Epoch 222: loss did not improve from 0.00932\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0223\n",
      "Epoch 223/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0354\n",
      "Epoch 223: loss did not improve from 0.00932\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0381\n",
      "Epoch 224/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0151\n",
      "Epoch 224: loss did not improve from 0.00932\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0150\n",
      "Epoch 225/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0131\n",
      "Epoch 225: loss did not improve from 0.00932\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0171\n",
      "Epoch 226/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0168\n",
      "Epoch 226: loss did not improve from 0.00932\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0156\n",
      "Epoch 227/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0123\n",
      "Epoch 227: loss did not improve from 0.00932\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0110\n",
      "Epoch 228/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0153\n",
      "Epoch 228: loss did not improve from 0.00932\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0166\n",
      "Epoch 229/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0213\n",
      "Epoch 229: loss did not improve from 0.00932\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0197\n",
      "Epoch 230/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0095\n",
      "Epoch 230: loss did not improve from 0.00932\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0134\n",
      "Epoch 231/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0084\n",
      "Epoch 231: loss did not improve from 0.00932\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0108\n",
      "Epoch 232/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0131\n",
      "Epoch 232: loss did not improve from 0.00932\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.0100\n",
      "Epoch 233/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0047\n",
      "Epoch 233: loss did not improve from 0.00932\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0095\n",
      "Epoch 234/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0134\n",
      "Epoch 234: loss improved from 0.00932 to 0.00891, saving model to best_model.h5\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0089\n",
      "Epoch 235/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0125\n",
      "Epoch 235: loss did not improve from 0.00891\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0095\n",
      "Epoch 236/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0130\n",
      "Epoch 236: loss did not improve from 0.00891\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0096\n",
      "Epoch 237/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0052\n",
      "Epoch 237: loss did not improve from 0.00891\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0114\n",
      "Epoch 238/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0084\n",
      "Epoch 238: loss did not improve from 0.00891\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0137\n",
      "Epoch 239/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0077\n",
      "Epoch 239: loss did not improve from 0.00891\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0124\n",
      "Epoch 240/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0134\n",
      "Epoch 240: loss did not improve from 0.00891\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0134\n",
      "Epoch 241/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0073\n",
      "Epoch 241: loss improved from 0.00891 to 0.00885, saving model to best_model.h5\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0089\n",
      "Epoch 242/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0057\n",
      "Epoch 242: loss did not improve from 0.00885\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0095\n",
      "Epoch 243/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0083\n",
      "Epoch 243: loss did not improve from 0.00885\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0100\n",
      "Epoch 244/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0142\n",
      "Epoch 244: loss did not improve from 0.00885\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0120\n",
      "Epoch 245/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0051\n",
      "Epoch 245: loss improved from 0.00885 to 0.00881, saving model to best_model.h5\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0088\n",
      "Epoch 246/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0126\n",
      "Epoch 246: loss did not improve from 0.00881\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0100\n",
      "Epoch 247/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0068\n",
      "Epoch 247: loss did not improve from 0.00881\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.0101\n",
      "Epoch 248/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0188\n",
      "Epoch 248: loss did not improve from 0.00881\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0161\n",
      "Epoch 249/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0201\n",
      "Epoch 249: loss did not improve from 0.00881\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0172\n",
      "Epoch 250/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0153\n",
      "Epoch 250: loss did not improve from 0.00881\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0135\n",
      "Epoch 251/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0194\n",
      "Epoch 251: loss did not improve from 0.00881\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.0176\n",
      "Epoch 252/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0114\n",
      "Epoch 252: loss did not improve from 0.00881\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0118\n",
      "Epoch 253/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0252\n",
      "Epoch 253: loss did not improve from 0.00881\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0227\n",
      "Epoch 254/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0307\n",
      "Epoch 254: loss did not improve from 0.00881\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0164\n",
      "Epoch 255/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0134\n",
      "Epoch 255: loss did not improve from 0.00881\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0145\n",
      "Epoch 256/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0263\n",
      "Epoch 256: loss did not improve from 0.00881\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0173\n",
      "Epoch 257/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0129\n",
      "Epoch 257: loss did not improve from 0.00881\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0118\n",
      "Epoch 258/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0111\n",
      "Epoch 258: loss did not improve from 0.00881\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0158\n",
      "Epoch 259/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0144\n",
      "Epoch 259: loss did not improve from 0.00881\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0202\n",
      "Epoch 260/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0129\n",
      "Epoch 260: loss did not improve from 0.00881\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0145\n",
      "Epoch 261/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0217\n",
      "Epoch 261: loss did not improve from 0.00881\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0239\n",
      "Epoch 262/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0182\n",
      "Epoch 262: loss did not improve from 0.00881\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0225\n",
      "Epoch 263/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0254\n",
      "Epoch 263: loss did not improve from 0.00881\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0180\n",
      "Epoch 264/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0198\n",
      "Epoch 264: loss did not improve from 0.00881\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0158\n",
      "Epoch 265/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0103\n",
      "Epoch 265: loss did not improve from 0.00881\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0098\n",
      "Epoch 266/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0158\n",
      "Epoch 266: loss did not improve from 0.00881\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0096\n",
      "Epoch 267/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0108\n",
      "Epoch 267: loss improved from 0.00881 to 0.00860, saving model to best_model.h5\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0086\n",
      "Epoch 268/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0112\n",
      "Epoch 268: loss did not improve from 0.00860\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0090\n",
      "Epoch 269/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0135\n",
      "Epoch 269: loss did not improve from 0.00860\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0098\n",
      "Epoch 270/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0107\n",
      "Epoch 270: loss did not improve from 0.00860\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0102\n",
      "Epoch 271/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0057\n",
      "Epoch 271: loss did not improve from 0.00860\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0102\n",
      "Epoch 272/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0154\n",
      "Epoch 272: loss improved from 0.00860 to 0.00824, saving model to best_model.h5\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0082\n",
      "Epoch 273/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0077\n",
      "Epoch 273: loss did not improve from 0.00824\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.0083\n",
      "Epoch 274/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0098\n",
      "Epoch 274: loss did not improve from 0.00824\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0096\n",
      "Epoch 275/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0082\n",
      "Epoch 275: loss did not improve from 0.00824\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0092\n",
      "Epoch 276/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0101\n",
      "Epoch 276: loss did not improve from 0.00824\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0097\n",
      "Epoch 277/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0074\n",
      "Epoch 277: loss did not improve from 0.00824\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0090\n",
      "Epoch 278/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0067\n",
      "Epoch 278: loss did not improve from 0.00824\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0109\n",
      "Epoch 279/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0060\n",
      "Epoch 279: loss did not improve from 0.00824\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0083\n",
      "Epoch 280/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0101\n",
      "Epoch 280: loss did not improve from 0.00824\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.0089\n",
      "Epoch 281/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0059\n",
      "Epoch 281: loss did not improve from 0.00824\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0086\n",
      "Epoch 282/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0068\n",
      "Epoch 282: loss did not improve from 0.00824\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0099\n",
      "Epoch 283/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0117\n",
      "Epoch 283: loss did not improve from 0.00824\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0117\n",
      "Epoch 284/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0284\n",
      "Epoch 284: loss did not improve from 0.00824\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0227\n",
      "Epoch 285/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0159\n",
      "Epoch 285: loss did not improve from 0.00824\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0127\n",
      "Epoch 286/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0116\n",
      "Epoch 286: loss did not improve from 0.00824\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0085\n",
      "Epoch 287/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0088\n",
      "Epoch 287: loss did not improve from 0.00824\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0092\n",
      "Epoch 288/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0241\n",
      "Epoch 288: loss did not improve from 0.00824\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0132\n",
      "Epoch 289/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0124\n",
      "Epoch 289: loss did not improve from 0.00824\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0085\n",
      "Epoch 290/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0133\n",
      "Epoch 290: loss did not improve from 0.00824\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.0105\n",
      "Epoch 291/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0071\n",
      "Epoch 291: loss improved from 0.00824 to 0.00807, saving model to best_model.h5\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0081\n",
      "Epoch 292/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0166\n",
      "Epoch 292: loss did not improve from 0.00807\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0146\n",
      "Epoch 293/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0166\n",
      "Epoch 293: loss did not improve from 0.00807\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0151\n",
      "Epoch 294/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0176\n",
      "Epoch 294: loss did not improve from 0.00807\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0154\n",
      "Epoch 295/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0259\n",
      "Epoch 295: loss did not improve from 0.00807\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0176\n",
      "Epoch 296/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0274\n",
      "Epoch 296: loss did not improve from 0.00807\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0147\n",
      "Epoch 297/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0198\n",
      "Epoch 297: loss did not improve from 0.00807\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.0139\n",
      "Epoch 298/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0129\n",
      "Epoch 298: loss did not improve from 0.00807\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0092\n",
      "Epoch 299/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0097\n",
      "Epoch 299: loss did not improve from 0.00807\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0097\n",
      "Epoch 300/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0084\n",
      "Epoch 300: loss did not improve from 0.00807\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0088\n",
      "Epoch 301/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0100\n",
      "Epoch 301: loss did not improve from 0.00807\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0088\n",
      "Epoch 302/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0066\n",
      "Epoch 302: loss did not improve from 0.00807\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.0090\n",
      "Epoch 303/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0074\n",
      "Epoch 303: loss did not improve from 0.00807\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0083\n",
      "Epoch 304/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0046\n",
      "Epoch 304: loss did not improve from 0.00807\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0088\n",
      "Epoch 305/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0117\n",
      "Epoch 305: loss did not improve from 0.00807\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0094\n",
      "Epoch 306/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0108\n",
      "Epoch 306: loss did not improve from 0.00807\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0116\n",
      "Epoch 307/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0098\n",
      "Epoch 307: loss did not improve from 0.00807\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0081\n",
      "Epoch 308/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0097\n",
      "Epoch 308: loss did not improve from 0.00807\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0087\n",
      "Epoch 309/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0157\n",
      "Epoch 309: loss did not improve from 0.00807\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0178\n",
      "Epoch 310/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0329\n",
      "Epoch 310: loss did not improve from 0.00807\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0224\n",
      "Epoch 311/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0092\n",
      "Epoch 311: loss did not improve from 0.00807\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0229\n",
      "Epoch 312/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0373\n",
      "Epoch 312: loss did not improve from 0.00807\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0282\n",
      "Epoch 313/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0402\n",
      "Epoch 313: loss did not improve from 0.00807\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0279\n",
      "Epoch 314/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0449\n",
      "Epoch 314: loss did not improve from 0.00807\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0287\n",
      "Epoch 315/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0188\n",
      "Epoch 315: loss did not improve from 0.00807\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0117\n",
      "Epoch 316/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0145\n",
      "Epoch 316: loss did not improve from 0.00807\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0158\n",
      "Epoch 317/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0102\n",
      "Epoch 317: loss did not improve from 0.00807\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0194\n",
      "Epoch 318/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0153\n",
      "Epoch 318: loss did not improve from 0.00807\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0152\n",
      "Epoch 319/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0067\n",
      "Epoch 319: loss did not improve from 0.00807\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0088\n",
      "Epoch 320/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0104\n",
      "Epoch 320: loss did not improve from 0.00807\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0113\n",
      "Epoch 321/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0062\n",
      "Epoch 321: loss did not improve from 0.00807\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0084\n",
      "Epoch 322/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0119\n",
      "Epoch 322: loss did not improve from 0.00807\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0091\n",
      "Epoch 323/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0069\n",
      "Epoch 323: loss did not improve from 0.00807\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0094\n",
      "Epoch 324/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0128\n",
      "Epoch 324: loss did not improve from 0.00807\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0184\n",
      "Epoch 325/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0087\n",
      "Epoch 325: loss did not improve from 0.00807\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0090\n",
      "Epoch 326/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0118\n",
      "Epoch 326: loss did not improve from 0.00807\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0103\n",
      "Epoch 327/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0075\n",
      "Epoch 327: loss did not improve from 0.00807\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0149\n",
      "Epoch 328/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0174\n",
      "Epoch 328: loss did not improve from 0.00807\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.0140\n",
      "Epoch 329/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0301\n",
      "Epoch 329: loss did not improve from 0.00807\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0178\n",
      "Epoch 330/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0077\n",
      "Epoch 330: loss did not improve from 0.00807\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0106\n",
      "Epoch 331/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0131\n",
      "Epoch 331: loss did not improve from 0.00807\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0104\n",
      "Epoch 332/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0094\n",
      "Epoch 332: loss did not improve from 0.00807\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0109\n",
      "Epoch 333/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0103\n",
      "Epoch 333: loss did not improve from 0.00807\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0084\n",
      "Epoch 334/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0071\n",
      "Epoch 334: loss did not improve from 0.00807\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0091\n",
      "Epoch 335/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0072\n",
      "Epoch 335: loss did not improve from 0.00807\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0088\n",
      "Epoch 336/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0084\n",
      "Epoch 336: loss did not improve from 0.00807\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0116\n",
      "Epoch 337/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0078\n",
      "Epoch 337: loss did not improve from 0.00807\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0103\n",
      "Epoch 338/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0070\n",
      "Epoch 338: loss did not improve from 0.00807\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0091\n",
      "Epoch 339/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0116\n",
      "Epoch 339: loss improved from 0.00807 to 0.00776, saving model to best_model.h5\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0078\n",
      "Epoch 340/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0090\n",
      "Epoch 340: loss did not improve from 0.00776\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0131\n",
      "Epoch 341/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0175\n",
      "Epoch 341: loss did not improve from 0.00776\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0114\n",
      "Epoch 342/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0078\n",
      "Epoch 342: loss did not improve from 0.00776\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0089\n",
      "Epoch 343/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0113\n",
      "Epoch 343: loss did not improve from 0.00776\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0132\n",
      "Epoch 344/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0113\n",
      "Epoch 344: loss did not improve from 0.00776\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0083\n",
      "Epoch 345/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0124\n",
      "Epoch 345: loss did not improve from 0.00776\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0094\n",
      "Epoch 346/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0082\n",
      "Epoch 346: loss did not improve from 0.00776\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0081\n",
      "Epoch 347/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0114\n",
      "Epoch 347: loss did not improve from 0.00776\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0099\n",
      "Epoch 348/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0054\n",
      "Epoch 348: loss did not improve from 0.00776\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0084\n",
      "Epoch 349/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0073\n",
      "Epoch 349: loss did not improve from 0.00776\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0083\n",
      "Epoch 350/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0059\n",
      "Epoch 350: loss did not improve from 0.00776\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0085\n",
      "Epoch 351/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0071\n",
      "Epoch 351: loss did not improve from 0.00776\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0096\n",
      "Epoch 352/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0199\n",
      "Epoch 352: loss did not improve from 0.00776\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0142\n",
      "Epoch 353/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0194\n",
      "Epoch 353: loss did not improve from 0.00776\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0264\n",
      "Epoch 354/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0184\n",
      "Epoch 354: loss did not improve from 0.00776\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.0155\n",
      "Epoch 355/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0127\n",
      "Epoch 355: loss did not improve from 0.00776\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0134\n",
      "Epoch 356/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0077\n",
      "Epoch 356: loss did not improve from 0.00776\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0179\n",
      "Epoch 357/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0248\n",
      "Epoch 357: loss did not improve from 0.00776\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0210\n",
      "Epoch 358/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0296\n",
      "Epoch 358: loss did not improve from 0.00776\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0303\n",
      "Epoch 359/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0296\n",
      "Epoch 359: loss did not improve from 0.00776\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0295\n",
      "Epoch 360/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0189\n",
      "Epoch 360: loss did not improve from 0.00776\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0256\n",
      "Epoch 361/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0098\n",
      "Epoch 361: loss did not improve from 0.00776\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0104\n",
      "Epoch 362/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0172\n",
      "Epoch 362: loss did not improve from 0.00776\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.0193\n",
      "Epoch 363/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0083\n",
      "Epoch 363: loss did not improve from 0.00776\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0105\n",
      "Epoch 364/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0103\n",
      "Epoch 364: loss did not improve from 0.00776\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0116\n",
      "Epoch 365/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0072\n",
      "Epoch 365: loss did not improve from 0.00776\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0090\n",
      "Epoch 366/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0084\n",
      "Epoch 366: loss did not improve from 0.00776\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0089\n",
      "Epoch 367/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0086\n",
      "Epoch 367: loss did not improve from 0.00776\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0103\n",
      "Epoch 368/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0103\n",
      "Epoch 368: loss did not improve from 0.00776\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0105\n",
      "Epoch 369/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0118\n",
      "Epoch 369: loss did not improve from 0.00776\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0091\n",
      "Epoch 370/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0068\n",
      "Epoch 370: loss did not improve from 0.00776\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0086\n",
      "Epoch 371/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0108\n",
      "Epoch 371: loss did not improve from 0.00776\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0102\n",
      "Epoch 372/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0122\n",
      "Epoch 372: loss did not improve from 0.00776\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.0086\n",
      "Epoch 373/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0065\n",
      "Epoch 373: loss improved from 0.00776 to 0.00746, saving model to best_model.h5\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0075\n",
      "Epoch 374/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0091\n",
      "Epoch 374: loss did not improve from 0.00746\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0107\n",
      "Epoch 375/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0102\n",
      "Epoch 375: loss did not improve from 0.00746\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0083\n",
      "Epoch 376/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0095\n",
      "Epoch 376: loss did not improve from 0.00746\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0087\n",
      "Epoch 377/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0072\n",
      "Epoch 377: loss did not improve from 0.00746\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0076\n",
      "Epoch 378/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0070\n",
      "Epoch 378: loss did not improve from 0.00746\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0091\n",
      "Epoch 379/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0060\n",
      "Epoch 379: loss did not improve from 0.00746\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0089\n",
      "Epoch 380/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0055\n",
      "Epoch 380: loss did not improve from 0.00746\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0082\n",
      "Epoch 381/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0054\n",
      "Epoch 381: loss did not improve from 0.00746\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0100\n",
      "Epoch 382/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0103\n",
      "Epoch 382: loss did not improve from 0.00746\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0158\n",
      "Epoch 383/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0193\n",
      "Epoch 383: loss did not improve from 0.00746\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0128\n",
      "Epoch 384/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0203\n",
      "Epoch 384: loss did not improve from 0.00746\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0105\n",
      "Epoch 385/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0117\n",
      "Epoch 385: loss did not improve from 0.00746\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0105\n",
      "Epoch 386/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0129\n",
      "Epoch 386: loss did not improve from 0.00746\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0103\n",
      "Epoch 387/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0214\n",
      "Epoch 387: loss did not improve from 0.00746\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0148\n",
      "Epoch 388/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0291\n",
      "Epoch 388: loss did not improve from 0.00746\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0193\n",
      "Epoch 389/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0078\n",
      "Epoch 389: loss did not improve from 0.00746\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0103\n",
      "Epoch 390/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0123\n",
      "Epoch 390: loss did not improve from 0.00746\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0087\n",
      "Epoch 391/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0151\n",
      "Epoch 391: loss did not improve from 0.00746\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0111\n",
      "Epoch 392/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0130\n",
      "Epoch 392: loss did not improve from 0.00746\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0093\n",
      "Epoch 393/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0196\n",
      "Epoch 393: loss did not improve from 0.00746\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0140\n",
      "Epoch 394/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0176\n",
      "Epoch 394: loss did not improve from 0.00746\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.0114\n",
      "Epoch 395/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0115\n",
      "Epoch 395: loss did not improve from 0.00746\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0100\n",
      "Epoch 396/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0194\n",
      "Epoch 396: loss did not improve from 0.00746\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0128\n",
      "Epoch 397/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0245\n",
      "Epoch 397: loss did not improve from 0.00746\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0172\n",
      "Epoch 398/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0063\n",
      "Epoch 398: loss did not improve from 0.00746\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0102\n",
      "Epoch 399/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0172\n",
      "Epoch 399: loss did not improve from 0.00746\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0144\n",
      "Epoch 400/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0106\n",
      "Epoch 400: loss did not improve from 0.00746\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0085\n",
      "Epoch 401/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0146\n",
      "Epoch 401: loss did not improve from 0.00746\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0096\n",
      "Epoch 402/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0055\n",
      "Epoch 402: loss improved from 0.00746 to 0.00721, saving model to best_model.h5\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0072\n",
      "Epoch 403/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0094\n",
      "Epoch 403: loss did not improve from 0.00721\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0088\n",
      "Epoch 404/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0104\n",
      "Epoch 404: loss did not improve from 0.00721\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0090\n",
      "Epoch 405/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0143\n",
      "Epoch 405: loss did not improve from 0.00721\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0106\n",
      "Epoch 406/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0059\n",
      "Epoch 406: loss did not improve from 0.00721\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0121\n",
      "Epoch 407/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0079\n",
      "Epoch 407: loss did not improve from 0.00721\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0094\n",
      "Epoch 408/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0094\n",
      "Epoch 408: loss did not improve from 0.00721\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0073\n",
      "Epoch 409/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0082\n",
      "Epoch 409: loss did not improve from 0.00721\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0094\n",
      "Epoch 410/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0123\n",
      "Epoch 410: loss did not improve from 0.00721\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0075\n",
      "Epoch 411/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0047\n",
      "Epoch 411: loss did not improve from 0.00721\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0077\n",
      "Epoch 412/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0065\n",
      "Epoch 412: loss did not improve from 0.00721\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0078\n",
      "Epoch 413/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0063\n",
      "Epoch 413: loss did not improve from 0.00721\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0080\n",
      "Epoch 414/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0090\n",
      "Epoch 414: loss did not improve from 0.00721\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0091\n",
      "Epoch 415/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0063\n",
      "Epoch 415: loss did not improve from 0.00721\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0113\n",
      "Epoch 416/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0087\n",
      "Epoch 416: loss did not improve from 0.00721\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0103\n",
      "Epoch 417/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0125\n",
      "Epoch 417: loss did not improve from 0.00721\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0175\n",
      "Epoch 418/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0256\n",
      "Epoch 418: loss did not improve from 0.00721\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0197\n",
      "Epoch 419/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0257\n",
      "Epoch 419: loss did not improve from 0.00721\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0269\n",
      "Epoch 420/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0364\n",
      "Epoch 420: loss did not improve from 0.00721\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0266\n",
      "Epoch 421/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0197\n",
      "Epoch 421: loss did not improve from 0.00721\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0172\n",
      "Epoch 422/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0059\n",
      "Epoch 422: loss did not improve from 0.00721\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0122\n",
      "Epoch 423/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0109\n",
      "Epoch 423: loss did not improve from 0.00721\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0147\n",
      "Epoch 424/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0148\n",
      "Epoch 424: loss did not improve from 0.00721\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0212\n",
      "Epoch 425/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0127\n",
      "Epoch 425: loss did not improve from 0.00721\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0154\n",
      "Epoch 426/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0043\n",
      "Epoch 426: loss did not improve from 0.00721\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0102\n",
      "Epoch 427/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0041\n",
      "Epoch 427: loss did not improve from 0.00721\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0138\n",
      "Epoch 428/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0101\n",
      "Epoch 428: loss did not improve from 0.00721\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0104\n",
      "Epoch 429/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0081\n",
      "Epoch 429: loss did not improve from 0.00721\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0088\n",
      "Epoch 430/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0056\n",
      "Epoch 430: loss did not improve from 0.00721\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0082\n",
      "Epoch 431/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0120\n",
      "Epoch 431: loss did not improve from 0.00721\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0083\n",
      "Epoch 432/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0108\n",
      "Epoch 432: loss did not improve from 0.00721\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.0075\n",
      "Epoch 433/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0089\n",
      "Epoch 433: loss did not improve from 0.00721\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0083\n",
      "Epoch 434/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0097\n",
      "Epoch 434: loss did not improve from 0.00721\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0083\n",
      "Epoch 435/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0044\n",
      "Epoch 435: loss did not improve from 0.00721\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0076\n",
      "Epoch 436/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0062\n",
      "Epoch 436: loss did not improve from 0.00721\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0082\n",
      "Epoch 437/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0058\n",
      "Epoch 437: loss improved from 0.00721 to 0.00679, saving model to best_model.h5\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.0068\n",
      "Epoch 438/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0114\n",
      "Epoch 438: loss did not improve from 0.00679\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0155\n",
      "Epoch 439/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0126\n",
      "Epoch 439: loss did not improve from 0.00679\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0183\n",
      "Epoch 440/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0211\n",
      "Epoch 440: loss did not improve from 0.00679\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0165\n",
      "Epoch 441/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0181\n",
      "Epoch 441: loss did not improve from 0.00679\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0157\n",
      "Epoch 442/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0163\n",
      "Epoch 442: loss did not improve from 0.00679\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0151\n",
      "Epoch 443/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0160\n",
      "Epoch 443: loss did not improve from 0.00679\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0178\n",
      "Epoch 444/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0304\n",
      "Epoch 444: loss did not improve from 0.00679\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0167\n",
      "Epoch 445/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0044\n",
      "Epoch 445: loss did not improve from 0.00679\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0085\n",
      "Epoch 446/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0085\n",
      "Epoch 446: loss did not improve from 0.00679\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0080\n",
      "Epoch 447/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0090\n",
      "Epoch 447: loss did not improve from 0.00679\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0076\n",
      "Epoch 448/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0081\n",
      "Epoch 448: loss did not improve from 0.00679\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0073\n",
      "Epoch 449/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0079\n",
      "Epoch 449: loss did not improve from 0.00679\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0082\n",
      "Epoch 450/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0073\n",
      "Epoch 450: loss did not improve from 0.00679\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0084\n",
      "Epoch 451/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0082\n",
      "Epoch 451: loss did not improve from 0.00679\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0114\n",
      "Epoch 452/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0085\n",
      "Epoch 452: loss did not improve from 0.00679\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0092\n",
      "Epoch 453/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0090\n",
      "Epoch 453: loss did not improve from 0.00679\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.0118\n",
      "Epoch 454/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0159\n",
      "Epoch 454: loss did not improve from 0.00679\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0171\n",
      "Epoch 455/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0167\n",
      "Epoch 455: loss did not improve from 0.00679\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0180\n",
      "Epoch 456/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0263\n",
      "Epoch 456: loss did not improve from 0.00679\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0187\n",
      "Epoch 457/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0249\n",
      "Epoch 457: loss did not improve from 0.00679\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0220\n",
      "Epoch 458/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0429\n",
      "Epoch 458: loss did not improve from 0.00679\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0256\n",
      "Epoch 459/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0165\n",
      "Epoch 459: loss did not improve from 0.00679\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0151\n",
      "Epoch 460/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0299\n",
      "Epoch 460: loss did not improve from 0.00679\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0172\n",
      "Epoch 461/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0203\n",
      "Epoch 461: loss did not improve from 0.00679\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0141\n",
      "Epoch 462/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0252\n",
      "Epoch 462: loss did not improve from 0.00679\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.0193\n",
      "Epoch 463/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0163\n",
      "Epoch 463: loss did not improve from 0.00679\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0122\n",
      "Epoch 464/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0103\n",
      "Epoch 464: loss did not improve from 0.00679\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.0085\n",
      "Epoch 465/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0065\n",
      "Epoch 465: loss did not improve from 0.00679\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.0090\n",
      "Epoch 466/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0108\n",
      "Epoch 466: loss improved from 0.00679 to 0.00666, saving model to best_model.h5\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0067\n",
      "Epoch 467/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0065\n",
      "Epoch 467: loss did not improve from 0.00666\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0075\n",
      "Epoch 468/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0106\n",
      "Epoch 468: loss did not improve from 0.00666\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0145\n",
      "Epoch 469/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0161\n",
      "Epoch 469: loss did not improve from 0.00666\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0179\n",
      "Epoch 470/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0159\n",
      "Epoch 470: loss did not improve from 0.00666\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0137\n",
      "Epoch 471/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0084\n",
      "Epoch 471: loss did not improve from 0.00666\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.0088\n",
      "Epoch 472/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0102\n",
      "Epoch 472: loss did not improve from 0.00666\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0105\n",
      "Epoch 473/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0070\n",
      "Epoch 473: loss did not improve from 0.00666\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0076\n",
      "Epoch 474/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0115\n",
      "Epoch 474: loss did not improve from 0.00666\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0093\n",
      "Epoch 475/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0137\n",
      "Epoch 475: loss did not improve from 0.00666\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0120\n",
      "Epoch 476/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0085\n",
      "Epoch 476: loss did not improve from 0.00666\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0074\n",
      "Epoch 477/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0122\n",
      "Epoch 477: loss did not improve from 0.00666\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0082\n",
      "Epoch 478/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0092\n",
      "Epoch 478: loss did not improve from 0.00666\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0083\n",
      "Epoch 479/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0130\n",
      "Epoch 479: loss did not improve from 0.00666\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0113\n",
      "Epoch 480/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0143\n",
      "Epoch 480: loss did not improve from 0.00666\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0116\n",
      "Epoch 481/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0137\n",
      "Epoch 481: loss did not improve from 0.00666\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0096\n",
      "Epoch 482/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0054\n",
      "Epoch 482: loss did not improve from 0.00666\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0096\n",
      "Epoch 483/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0090\n",
      "Epoch 483: loss did not improve from 0.00666\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0110\n",
      "Epoch 484/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0121\n",
      "Epoch 484: loss did not improve from 0.00666\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0087\n",
      "Epoch 485/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0071\n",
      "Epoch 485: loss did not improve from 0.00666\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0082\n",
      "Epoch 486/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0059\n",
      "Epoch 486: loss did not improve from 0.00666\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0092\n",
      "Epoch 487/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0051\n",
      "Epoch 487: loss did not improve from 0.00666\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.0078\n",
      "Epoch 488/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0039\n",
      "Epoch 488: loss did not improve from 0.00666\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0069\n",
      "Epoch 489/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0051\n",
      "Epoch 489: loss did not improve from 0.00666\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0092\n",
      "Epoch 490/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0082\n",
      "Epoch 490: loss did not improve from 0.00666\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0085\n",
      "Epoch 491/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0096\n",
      "Epoch 491: loss did not improve from 0.00666\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0067\n",
      "Epoch 492/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0040\n",
      "Epoch 492: loss did not improve from 0.00666\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0095\n",
      "Epoch 493/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0111\n",
      "Epoch 493: loss did not improve from 0.00666\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0084\n",
      "Epoch 494/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0080\n",
      "Epoch 494: loss did not improve from 0.00666\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0069\n",
      "Epoch 495/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0076\n",
      "Epoch 495: loss did not improve from 0.00666\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0069\n",
      "Epoch 496/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0055\n",
      "Epoch 496: loss did not improve from 0.00666\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.0093\n",
      "Epoch 497/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0123\n",
      "Epoch 497: loss did not improve from 0.00666\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0101\n",
      "Epoch 498/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0078\n",
      "Epoch 498: loss did not improve from 0.00666\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0068\n",
      "Epoch 499/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0051\n",
      "Epoch 499: loss did not improve from 0.00666\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0084\n",
      "Epoch 500/500\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0052\n",
      "Epoch 500: loss did not improve from 0.00666\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0074\n",
      "Best model is from epoch 466 and loss is 0.006661346182227135\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "Predicted number of faults: [130.72978]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import sys\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dense, Activation, LSTM\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.initializers import RandomNormal, Constant\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from scipy.stats import truncnorm\n",
    "\n",
    "import srdata\n",
    "\n",
    "# 1: シミュレーション\n",
    "    # 1: 指数分布モデル\n",
    "    # 2: ガンマ分布モデル\n",
    "    # 3: 切断正規分布モデル\n",
    "# 2: 実データ\n",
    "    # 1: Lyu/J1.csv\n",
    "    # 2: Lyu/J2.csv\n",
    "    # 3: Lyu/J3.csv\n",
    "    # 4: Lyu/J4.csv\n",
    "    # 5: Lyu/J5.csv\n",
    "data_type = 1\n",
    "data_index = 3\n",
    "\n",
    "# 学習データとテストデータの割合（全体のデータ数ににtrain_ratioをかけて小数点以下切り捨てした数が学習データ数）\n",
    "train_ratio = 1\n",
    "\n",
    "# ハイパーパラメータ\n",
    "hidden_units = 500\n",
    "epochs = 500\n",
    "batch_size = 32\n",
    "\n",
    "# 正規化の有無\n",
    "normalization = True\n",
    "\n",
    "# 最良モデルの保存\n",
    "save_best_model = True\n",
    "\n",
    "# 早期終了の有無（未実装）\n",
    "early_stopping = False\n",
    "\n",
    "# 早期終了のパラメータ\n",
    "# patience = 10\n",
    "\n",
    "# 学習データの重みづけの有無\n",
    "sample_weight = True\n",
    "\n",
    "# 学習のverbose\n",
    "verbose = 1\n",
    "\n",
    "# 追加の予測値\n",
    "additional_prediction = True\n",
    "\n",
    "####################################################################################################\n",
    "\n",
    "def generate_data(data_type, dataset_index, size=100, scale=50, shape=2, loc=0):\n",
    "    # シミュレーション\n",
    "    if data_type == 1:\n",
    "        # シードの固定\n",
    "        seed = 1\n",
    "        np.random.seed(seed)\n",
    "\n",
    "        # 指数分布モデル\n",
    "        if dataset_index == 1:\n",
    "            # データの生成\n",
    "            samples = np.random.exponential(scale, size)\n",
    "            sorted_samples = np.sort(samples)\n",
    "\n",
    "        # ガンマ分布モデル\n",
    "        # 正式な分布と違う？(https://github.com/SwReliab/SRATS2017/blob/master/docs/pdfs/srats_model.pdf)\n",
    "        # 将来的に逆変換サンプリングを用いて実装する予定\n",
    "        elif dataset_index == 2:\n",
    "            # データの生成\n",
    "            samples = np.random.gamma(shape, scale, size)\n",
    "            sorted_samples = np.sort(samples)\n",
    "\n",
    "        # 切断正規分布モデル\n",
    "        # 正式な分布と違う？(https://github.com/SwReliab/SRATS2017/blob/master/docs/pdfs/srats_model.pdf)\n",
    "        elif dataset_index == 3:\n",
    "            # データの生成\n",
    "            truncnorm_dist = truncnorm((0 - loc) / scale, (np.inf - 0) / scale, loc=loc, scale=scale)\n",
    "            samples = truncnorm_dist.rvs(size)\n",
    "            sorted_samples = np.sort(samples)\n",
    "\n",
    "        # データの作成\n",
    "        X = sorted_samples.reshape(-1, 1)\n",
    "        y = np.arange(1, len(sorted_samples) + 1).reshape(-1, 1)\n",
    "\n",
    "    # 実データ\n",
    "    elif data_type == 2:\n",
    "        dataset_names = [\"Lyu/J1.csv\", \"Lyu/J2.csv\", \"Lyu/J3.csv\", \"Lyu/J4.csv\", \"Lyu/J5.csv\"]\n",
    "        data_df = srdata.get_dataset(dataset_names[dataset_index - 1])\n",
    "        data = data_df.iloc[:, 0].values\n",
    "        cum_data = data.cumsum()\n",
    "        X = np.arange(1, len(cum_data) + 1).reshape(-1, 1)\n",
    "        y = cum_data.reshape(-1, 1)\n",
    "\n",
    "    return X, y\n",
    "\n",
    "####################################################################################################\n",
    "\n",
    "# tensorflowのランダムシードの固定\n",
    "tf.keras.utils.set_random_seed(1)\n",
    "\n",
    "# データの生成\n",
    "X, y = generate_data(data_type, data_index)\n",
    "\n",
    "# データの分割\n",
    "train_size = int(len(X) * train_ratio)  # 小数点以下切り捨て\n",
    "\n",
    "# 正規化\n",
    "if normalization:\n",
    "    scaler_X = MinMaxScaler(feature_range=(0, 1))\n",
    "    scaler_y = MinMaxScaler(feature_range=(0, 1))\n",
    "    X = scaler_X.fit_transform(X)\n",
    "    y = scaler_y.fit_transform(y)\n",
    "\n",
    "# データの分割\n",
    "X_train = X[:train_size]\n",
    "y_train = y[:train_size]\n",
    "X_test = X[train_size:]\n",
    "y_test = y[train_size:]\n",
    "\n",
    "# モデルの構築（Functional API）\n",
    "input_layer = Input(shape=(1,))\n",
    "x = Dense(hidden_units, activation=\"relu\")(input_layer)\n",
    "x = Dense(hidden_units, activation=\"relu\")(x)\n",
    "x = Dense(hidden_units, activation=\"relu\")(x)\n",
    "x = Dense(1, activation=\"sigmoid\")(x)\n",
    "output_layer = Dense(1, use_bias=False, kernel_initializer=Constant(value=1.0))(x)\n",
    "\n",
    "model = Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "# モデルのコンパイル\n",
    "model.compile(loss='mse', optimizer='adam')\n",
    "\n",
    "# モデルのサマリーをテキストファイルに保存\n",
    "with open('model_summary.txt', 'w') as f:\n",
    "    # 標準出力を一時的にファイルにリダイレクト\n",
    "    old_stdout = sys.stdout\n",
    "    sys.stdout = f\n",
    "\n",
    "    # モデルのサマリーを出力\n",
    "    model.summary()\n",
    "\n",
    "    # 標準出力を元に戻す\n",
    "    sys.stdout = old_stdout\n",
    "\n",
    "# ModelCheckpointの設定\n",
    "callbacks_list = []\n",
    "if save_best_model:\n",
    "    checkpoint = ModelCheckpoint('best_model.h5', monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
    "    callbacks_list.append(checkpoint)\n",
    "\n",
    "# サンプルごとの重み\n",
    "sample_weight_array = None\n",
    "if sample_weight:\n",
    "    sample_weight_array = np.array([i for i in range(1, len(X_train) + 1)])\n",
    "\n",
    "# 学習\n",
    "history = model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, verbose=verbose, sample_weight=sample_weight_array, callbacks=callbacks_list)\n",
    "\n",
    "if (save_best_model):\n",
    "    model = load_model('best_model.h5')\n",
    "    min_loss_index = np.argmin(history.history['loss'])\n",
    "    print(\"Best model is from epoch {} and loss is {}\".format(min_loss_index + 1, history.history['loss'][min_loss_index]))\n",
    "\n",
    "# パラメータを保存\n",
    "# h5形式で保存\n",
    "model.save_weights('weights/weights.h5')\n",
    "# テキスト形式で保存\n",
    "weights = model.get_weights()\n",
    "with open('weights/model_weights.txt', 'w') as f:\n",
    "    for layer_weights in weights:\n",
    "        np.savetxt(f, layer_weights, fmt='%s')\n",
    "\n",
    "# 損失関数をプロット（横軸：エポック，縦軸：損失関数）\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(range(1, epochs + 1), history.history['loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "if MinMaxScaler:\n",
    "    plt.ylim(0, 0.01)   # 正規化する場合ylimを制限しないと損失関数が小さくなりすぎて見えなくなる\n",
    "plt.legend(['Train'], loc='upper left')\n",
    "\n",
    "# 予測（学習データも含む）\n",
    "pred_X = X\n",
    "if additional_prediction and normalization:\n",
    "    pred_X = np.append(pred_X, np.linspace(1, 2, 10).reshape(-1, 1))\n",
    "predictions = model.predict(pred_X)\n",
    "\n",
    "# 推定フォールト数の表示\n",
    "if normalization:\n",
    "    print(\"Predicted number of faults: {}\".format(scaler_X.inverse_transform(predictions)[-1]))\n",
    "else :\n",
    "    print(\"Predicted number of faults: {}\".format(predictions[-1]))\n",
    "\n",
    "# 予測値のプロット\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(X_train, y_train, color=\"red\", label='True_train', marker='o', markersize=2)\n",
    "plt.plot(X_test, y_test, color=\"blue\", label='True_test', marker='o', markersize=2)\n",
    "plt.plot(pred_X, predictions, color=\"green\", label='Predicted', marker='o', markersize=2)\n",
    "plt.title('Prediction')\n",
    "plt.xlabel('Testing Time')\n",
    "plt.ylabel('Cumulative Number of Failures')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
